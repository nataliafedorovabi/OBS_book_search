import logging
from typing import Dict, List, Any
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, Application
from src.tree_search import TreeSearcher
from src.llm import LLMClient
from src.rate_limiter import RateLimiter
from src.config import ADMIN_TELEGRAM_IDS

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
searcher: TreeSearcher = None
llm_client: LLMClient = None
rate_limiter: RateLimiter = None
_bot_app: Application = None

# –•—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∫–Ω–æ–ø–æ–∫
_search_context: Dict[int, Dict[str, Any]] = {}


def init_services(tree_searcher: TreeSearcher, llm: LLMClient, app: Application = None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤."""
    global searcher, llm_client, rate_limiter, _bot_app
    searcher = tree_searcher
    llm_client = llm
    rate_limiter = RateLimiter()
    _bot_app = app
    logger.info("–°–µ—Ä–≤–∏—Å—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start."""
    stats = searcher.tree.get_stats() if searcher else {}

    await update.message.reply_text(
        f"–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫—É—Ä—Å–∞ '–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–µ–π –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º'.\n\n"
        f"–í –±–∞–∑–µ: {stats.get('chapters', 0)} –≥–ª–∞–≤, {stats.get('chunks', 0)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.\n\n"
        f"–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º –∫—É—Ä—Å–∞, –∏ —è –Ω–∞–π–¥—É –æ—Ç–≤–µ—Ç –≤ –∫–Ω–∏–≥–∞—Ö.\n\n"
        f"–ö–æ–º–∞–Ω–¥—ã:\n"
        f"/help - –∫–∞–∫ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã\n"
        f"/status - —Å—Ç–∞—Ç—É—Å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help."""
    await update.message.reply_text(
        "–ö–∞–∫ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã:\n\n"
        "- –§–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ: '–ö–∞–∫–∏–µ —Ä–æ–ª–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä?'\n"
        "- –ú–æ–∂–Ω–æ —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å –ø—Ä–æ —Ç–µ—Ä–º–∏–Ω—ã: '–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ?'\n"
        "- –ú–æ–∂–Ω–æ –ø—Ä–æ—Å–∏—Ç—å —Å—Ä–∞–≤–Ω–∏—Ç—å: '–í —á—ë–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –ª–∏–¥–µ—Ä–æ–º –∏ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º?'\n\n"
        "–Ø –æ—Ç–≤–µ—á–∞—é —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–Ω–∏–≥ –∫—É—Ä—Å–∞. "
        "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö, —è —á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂—É."
    )


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /status."""
    stats = searcher.tree.get_stats() if searcher else {}

    if stats:
        await update.message.reply_text(
            f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∞–∫—Ç–∏–≤–Ω–∞.\n\n"
            f"–ö–Ω–∏–≥: {stats.get('books', 0)}\n"
            f"–ì–ª–∞–≤: {stats.get('chapters', 0)}\n"
            f"–°–µ–∫—Ü–∏–π: {stats.get('sections', 0)}\n"
            f"–§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {stats.get('chunks', 0)}\n\n"
            f"–í–µ—Ä—Å–∏—è –¥–µ—Ä–µ–≤–∞: {stats.get('version', 'N/A')}\n"
            f"–°–æ–∑–¥–∞–Ω–æ: {stats.get('created_at', 'N/A')[:10]}"
        )
    else:
        await update.message.reply_text("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")


async def usage_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–¥–ª—è –∞–¥–º–∏–Ω–æ–≤)."""
    user_id = str(update.effective_user.id)

    if ADMIN_TELEGRAM_IDS and user_id not in ADMIN_TELEGRAM_IDS:
        return

    usage = rate_limiter.get_usage_info()

    await update.message.reply_text(
        f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ {usage['date']}:\n\n"
        f"–ó–∞–ø—Ä–æ—Å–æ–≤: {usage['requests_today']}/{usage['limit']}\n"
        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {usage['percent_used']}%\n"
        f"–û—Å—Ç–∞–ª–æ—Å—å: {usage['remaining']}"
    )


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    question = update.message.text.strip()

    if not question:
        return

    if not searcher:
        await update.message.reply_text("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
    if not rate_limiter.can_make_request():
        await update.message.reply_text(
            "–î–æ—Å—Ç–∏–≥–Ω—É—Ç –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≤—Ç—Ä–∞."
        )
        return

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º "–ø–µ—á–∞—Ç–∞–µ—Ç"
    await context.bot.send_chat_action(
        chat_id=update.effective_chat.id,
        action="typing"
    )

    logger.info(f"–í–æ–ø—Ä–æ—Å: {question[:50]}...")

    # –ü–æ–∏—Å–∫ –ø–æ –¥–µ—Ä–µ–≤—É
    results = searcher.search(question, top_chapters=4, top_chunks=6)

    if not results:
        await update.message.reply_text(
            "–í –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö –∫—É—Ä—Å–∞ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        )
        return

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
    context_chunks = []
    chapters_found = {}

    for r in results:
        context_chunks.append({
            'text': r.text,
            'metadata': {
                'book_title': r.book_title,
                'chapter': r.chapter_title,
                'section': r.section_title
            },
            'score': r.score
        })

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≥–ª–∞–≤–∞–º
        ch_title = r.chapter_title
        if ch_title not in chapters_found:
            chapters_found[ch_title] = {
                'summary': r.chapter_summary,
                'chunks': []
            }
        chapters_found[ch_title]['chunks'].append(r)

    logger.info(f"–ù–∞–π–¥–µ–Ω–æ: {len(results)} —á–∞–Ω–∫–æ–≤ –∏–∑ {len(chapters_found)} –≥–ª–∞–≤")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    answer = llm_client.generate_answer(question, context_chunks, is_expanded_search=True)
    rate_limiter.record_request()

    await update.message.reply_text(answer, parse_mode="Markdown")


async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏."""
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id
    search_ctx = _search_context.get(user_id)

    if not search_ctx:
        await query.edit_message_reply_markup(reply_markup=None)
        await query.message.reply_text("–ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Å—Ç–∞—Ä–µ–ª. –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –∑–∞–Ω–æ–≤–æ.")
        return

    callback_data = query.data

    if callback_data.startswith("chapter_"):
        # –ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø–æ –≥–ª–∞–≤–µ
        chapter_idx = int(callback_data.split("_")[1])
        chapters_list = list(search_ctx['chapters'].keys())

        if chapter_idx >= len(chapters_list):
            await query.message.reply_text("–ì–ª–∞–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            return

        chapter_name = chapters_list[chapter_idx]
        chapter_data = search_ctx['chapters'][chapter_name]

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º summary –≥–ª–∞–≤—ã –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
        summary = chapter_data.get('summary', '')
        chunks = chapter_data.get('chunks', [])

        response = f"üìñ *{chapter_name}*\n\n"
        if summary:
            response += f"_{summary[:300]}..._\n\n" if len(summary) > 300 else f"_{summary}_\n\n"

        response += "**–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:**\n\n"
        for i, chunk in enumerate(chunks[:3], 1):
            text_preview = chunk.text[:200] + "..." if len(chunk.text) > 200 else chunk.text
            response += f"{i}. {text_preview}\n\n"

        await query.message.reply_text(response, parse_mode="Markdown")

    elif callback_data == "search_more":
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        original_query = search_ctx['query']

        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )

        # –ò—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö –≥–ª–∞–≤–∞—Ö
        more_results = searcher.search(original_query, top_chapters=6, top_chunks=8)

        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ
        shown_ids = {r.chunk_id for r in search_ctx['results']}
        new_results = [r for r in more_results if r.chunk_id not in shown_ids]

        if not new_results:
            await query.message.reply_text(
                "–î—Ä—É–≥–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            )
            return

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_chunks = [{
            'text': r.text,
            'metadata': {
                'book_title': r.book_title,
                'chapter': r.chapter_title
            },
            'score': r.score
        } for r in new_results[:5]]

        answer = llm_client.generate_answer(original_query, context_chunks, is_expanded_search=True)
        rate_limiter.record_request()

        await query.message.reply_text(f"üîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n\n{answer}")
